{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "from itertools import count\n",
    "from tkinter import Image\n",
    "import PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = LinearSVC()\n",
    "    \n",
    "    def train_model(self, counters):\n",
    "        img_list = np.array([])\n",
    "        class_list = np.array([])\n",
    "\n",
    "        for i in range(1, counters[0]):\n",
    "            img = cv2.imread(f\"1/frame{i}.jpg\")[:,:,0]\n",
    "            img = img.reshape(16950)\n",
    "            img_list = np.append(img_list, [img])\n",
    "            class_list = np.append(class_list, 1)\n",
    "\n",
    "\n",
    "        for i in range(1, counters[1]):\n",
    "            img = cv2.imread(f\"2/frame{i}.jpg\")[:,:,0]\n",
    "            img = img.reshape(16950)\n",
    "            img_list = np.append(img_list, [img])\n",
    "            class_list = np.append(class_list, 2)\n",
    "        \n",
    "        img_list = img_list.reshape(counters[0] + counters[1] - 2, 16950)\n",
    "        self.model.fit(img_list, class_list)\n",
    "        print(\"Model successfully trained!\")\n",
    "\n",
    "    def predict(self, frame):\n",
    "        frame = frame[1]\n",
    "        cv2.imwrite(\"frame.jpg\", cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY))\n",
    "        img = PIL.Image.open(\"frame.jpg\")\n",
    "        img.thumbnail((150,150), PIL.Image.ANTIALIAS)\n",
    "        img.save(\"frame.jpg\")\n",
    "\n",
    "        img = cv2.imread(\"frame.jpg\")[:,:,0]\n",
    "        img = img.reshape(16950)\n",
    "        prediction = self.model.predict([img])\n",
    "        return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully renamed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_dir = \"C:\\\\Users\\\\HP\\\\Desktop\\\\AI Projects\\\\AI Bench Press RPE Calculator\"\n",
    "def rename_img(state: str):\n",
    "    i = 1\n",
    "    try:\n",
    "        for imgpath in os.listdir(os.path.join(base_dir, f\"new {state} pics\")):\n",
    "            new_base_path = os.path.join(base_dir, f\"new {state} pics\")\n",
    "            os.rename(os.path.join(new_base_path, imgpath), os.path.join(new_base_path, f\"{state}_{i}.jpg\"))\n",
    "            i += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    else:\n",
    "        print(\"Successfully renamed!\")\n",
    "\n",
    "rename_img(\"contracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extended_1.jpg\n",
      "./new extended pics\n"
     ]
    }
   ],
   "source": [
    "state=\"extended\"\n",
    "folder_path = f\"./new {state} pics\"\n",
    "i = 0\n",
    "for imgpath in os.listdir(folder_path):\n",
    "    print(imgpath)\n",
    "    i += 1\n",
    "    if i == 1:\n",
    "        break\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "img_array = np.array([])\n",
    "\n",
    "# preprocesses the images and appends them to the img_array\n",
    "\n",
    "folder_path = f\"./new contracted pics\"\n",
    "for imgpath in os.listdir(folder_path):\n",
    "    img = cv2.imread(os.path.join(folder_path, imgpath))[:,:,0]\n",
    "    # cv2.imshow(\"image\", img)\n",
    "    # dimensions of image - 2250*4000*3\n",
    "    img = cv2.resize(img, (500,400))\n",
    "    img = img[120:,:]\n",
    "    img = img/255.0\n",
    "    img_array = np.append(img_array, [img])\n",
    "\n",
    "\n",
    "folder_path = f\"./new extended pics\"\n",
    "for imgpath in os.listdir(folder_path):\n",
    "    img = cv2.imread(os.path.join(folder_path, imgpath))[:,:,0]\n",
    "    # cv2.imshow(\"image\", img)\n",
    "    # dimensions of image - 2250*4000*3\n",
    "    img = cv2.resize(img, (500,400))\n",
    "    img = img[120:,:]\n",
    "    img = img/255.0\n",
    "    img_array = np.append(img_array, [img])       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000000\n"
     ]
    }
   ],
   "source": [
    "print(len(img_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array = img_array.reshape((200,280*500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 140000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "class_array = np.array([])\n",
    "folder_path = f\"./new contracted pics\"\n",
    "for imgpath in os.listdir(folder_path):\n",
    "    class_array = np.append(class_array, 1)\n",
    "\n",
    "folder_path = f\"./new extended pics\"\n",
    "for imgpath in os.listdir(folder_path):\n",
    "    class_array = np.append(class_array, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully trained!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "y_train, y_test = class_array[: 160], class_array[160:]\n",
    "x_train, x_test = img_array[:160,:], img_array[160:,:]\n",
    "model = LinearSVC(random_state= 1569)\n",
    "model.fit(x_train, y_train)\n",
    "print(\"Model successfully trained!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[40]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "y_pred=model.predict(x_test)\n",
    "print(accuracy_score(y_pred,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[40]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2250, 4000)\n",
      "(280, 500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "path = \"C:\\\\Users\\\\HP\\\\Desktop\\\\AI Projects\\\\AI Bench Press RPE Calculator\\\\new contracted pics\\\\contracted_1.jpg\"\n",
    "img = cv2.imread(path)[:,:,0]\n",
    "print(img.shape)\n",
    "# cv2.imshow(\"image\", img)\n",
    "# dimensions of image - 2250*4000*3\n",
    "img = cv2.resize(img, (500,400))\n",
    "img = img[120:,:]\n",
    "print(img.shape)\n",
    "\n",
    "# cropped_image = img[1000:2000,2000:3000]\n",
    "cv2.imshow(\"image\", img)\n",
    "# cv2.imshow(\"cropped image\", cropped_image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
